# GAN
Generative Adversarial Network
## REFERENCE

- [https://ysbsb.github.io/gan/2020/06/17/GAN-newbie-guide.html](https://ysbsb.github.io/gan/2020/06/17/GAN-newbie-guide.html)

# Generative Adversarial Network : ëŒ€ë¦½ìƒì„±ì‹ ê²½ë§

---

> ê¸°ì¡´ì˜ GANì— CNNì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ ë„ì…í•œ DCGAN (Deep Convolutonal Generative Adversarial Networks)ë¥¼ ì œì•ˆí•¨. Supervised learningì—ì„œ CNNì´ í° ì—­í• ì„ í•˜ê³  ìˆëŠ”ë°, unsupervised learningì—ì„œëŠ” CNNì´ ì£¼ëª©ì„ ëœ ë°›ê³  ìˆì—ˆìŒ. ì´ë ‡ê²Œ CNNì—ì„œ ì„±ê³µì ì¸ ì ì„ GANì—ë„ ì ìš©í•˜ì—¬ ê¸°ì¡´ GANë³´ë‹¤ í›¨ì”¬ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ê²Œ ë˜ì—ˆìŒ. ê·¸ ì „ê¹Œì§€ GANë§Œ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì•˜ìœ¼ë‚˜, DCGAN ì´í›„ë¡œë¶€í„° GANì˜ ë°œì „ì´ ë§ì´ ë˜ì—ˆìŒ.
> 
> ![Screen Shot 2022-01-14 at 14 15 13](https://user-images.githubusercontent.com/61719257/149455594-7945c343-0652-421e-8e36-8eb57e97028f.png)


## 1. GAN main idea

> Ian Goodfellowê°€ ìµœì´ˆë¡œ GAN (Generative Adversarial Nets)ë¥¼ ì œì•ˆí•œ ë…¼ë¬¸. ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ìƒì„±ì Generatorì™€ ìƒ˜í”Œ ë°ì´í„°ì™€ ìƒì„±ìê°€ ìƒì„±í•œ ì´ë¯¸ì§€ë¥¼ êµ¬ë¶„í•˜ëŠ” êµ¬ë³„ì Discriminator ë‘ ê°œì˜ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ë¥¼ ì œì•ˆí•¨. ìƒì„±ìëŠ” êµ¬ë³„ìë¥¼ ì†ì´ë©´ì„œ ì´ë¯¸ì§€ë¥¼ ì˜ ìƒì„±í•˜ë ¤ê³  í•˜ë©°, êµ¬ë³„ìëŠ” ì£¼ì–´ì§„ ì´ë¯¸ì§€ì ì§„ì§œì¸ì§€ ê°€ê¹Œì¸ì§€ íŒë³„í•¨.

**Generator : ìƒì„±ì**
> 
> 
> > random noise ê°’ìœ¼ë¡œë¶€í„° í•™ìŠµí•˜ëŠ” ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ì—­í• 
> > 
> 
> **Discriminator : íŒë³„ì**
> 
> > Generator ë¡œë¶€í„° ìƒì„±ëœ ì´ë¯¸ì§€ì™€ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ì§„ì§œ ì´ë¯¸ì§€ ì¤‘ ë¬´ì—‡ì´ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ íŒë³„í•˜ëŠ” ì—­í• 
> > 

<aside>
ğŸ“Œ ìƒì„±ìê°€ ì„¸ìƒì— ìˆì„ ë²•í•œ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ ë‚´ë©´ íŒë³„ìê°€ ì§„ì§œ ì´ë¯¸ì§€ì™€ ë¹„êµí•˜ì—¬ ì´ë¥¼ íŒë³„í•˜ê²Œ ëœë‹¤.
ì´ ê³¼ì •ì—ì„œ ìƒì„±ìëŠ” íŒë³„ìë¥¼ ì†ì´ê¸° ìœ„í•´ ê³„ì† í–¥ìƒëœ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê²Œ ë˜ë©´ì„œ í›ˆë ¨ì´ ì§„í–‰ëœë‹¤.

</aside>

## 2. Generator

```python
# generator
def make_generator_model():
    """
    ìƒì„±ì í•¨ìˆ˜
    """
    generator_input = Input(shape=(100,), name='generator_input')
    x = generator_input
    x = Dense(4*4*256, use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Reshape((4,4,256))(x)
    
    x = UpSampling2D()(x)
    x = Conv2D(128, (3,3), strides=1, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    
    x = UpSampling2D()(x)
    x = Conv2D(64, (3,3), strides=1, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same', use_bias=False)(x)
    x = Conv2DTranspose(1, (3,3), strides=1, padding='same', use_bias=False, activation='sigmoid')(x)
    generator_output = x
    
    return tf.keras.models.Model(generator_input, generator_output)
```

upsampling ì„ í†µí•´ ëœë¤í•œ noiseë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ ë‚¸ë‹¤. 

## 3. Discriminator

```python
# discriminator
def make_discriminator_model():
    """
    íŒë³„ì í•¨ìˆ˜
    """
    discriminator_input = Input(shape=(32,32,1), name='discriminator_input')
    x = discriminator_input
    x = Conv2D(32, (4,4), strides=2, padding='same')(x)
    x = ReLU()(x)
    x = Dropout(0.3)(x)
    
    x = Conv2D(64, (4,4), strides=2, padding='same')(x)
    x = ReLU()(x)
    x = Dropout(0.3)(x)
    
    x = Flatten()(x)
    x = Dense(1)(x) # activation=sigmoid
    discriminator_output = x
    
    return tf.keras.models.Model(discriminator_input, discriminator_output)
```

ë‹¨ìˆœí•œ CNN êµ¬ì¡°ì´ë‹¤. ì…ë ¥ë°›ì€ ì´ë¯¸ì§€ê°€ ì§„ì§œì¸ì§€ ìƒì„±ëœ ê°€ì§œ ì´ë¯¸ì§€ì¸ì§€ íŒë³„í•˜ëŠ” ì—­í• ì„ í•˜ê²Œ ëœë‹¤.

ìµœì¢… output ì€ ì´ì§„ë¶„ë¥˜ê°€ ë˜ì–´ 0~1 ì‚¬ì´ ê°’ì„ ê°–ê²Œ ëœë‹¤.

## 4. Loss functions

```python
# loss functions
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    """íŒë³„ì ì†ì‹¤í•¨ìˆ˜"""
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    """ìƒì„±ì ì†ì‹¤í•¨ìˆ˜"""
    return cross_entropy(tf.ones_like(fake_output), fake_output)

# Optimizers
generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)
```

ìƒì„±ìì™€ íŒë³„ì ë‘ê°œì˜ ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— ê°ê° ì†ì‹¤í•¨ìˆ˜ê°€ ì¡´ì¬í•œë‹¤.

### íŒë³„ìì˜ ì†ì‹¤í•¨ìˆ˜

> ì§„ì§œ ì´ë¯¸ì§€ê°€ íŒë³„ìë¥¼ ê±°ì³ ë‚˜ì˜¨ output ì€ 1 ì´ ë˜ë„ë¡ ì†ì‹¤í•¨ìˆ˜ë¥¼ êµ¬ì„±í•˜ê³ 
> 
> 
> ìƒì„±ëœ ì´ë¯¸ì§€ê°€ íŒë³„ìë¥¼ ê±°ì³ ë‚˜ì˜¨ output ì€ 0 ì´ ë˜ë„ë¡ ì†ì‹¤í•¨ìˆ˜ë¥¼ êµ¬ì„±í•œë‹¤.
> ê°ê°ì˜ ì†ì‹¤í•¨ìˆ˜ë¥¼ ê±°ì¹œ ê°’ì„ ë”í•´ì¤€ë‹¤.
> 

### ìƒì„±ìì˜ ì†ì‹¤í•¨ìˆ˜

> ìƒì„±ìëŠ” ì§„ì§œì²˜ëŸ¼ ë³´ì´ë„ë¡ í›ˆë ¨ì´ ë˜ì•¼í•˜ê¸° ë•Œë¬¸ì— íŒë³„ìë¥¼ ê±°ì³ë‚˜ì˜¨ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ output ì´ 1 ì´ ë˜ë„ë¡ ì†ì‹¤í•¨ìˆ˜ë¥¼ êµ¬ì„±í•´ì¤€ë‹¤.
> 

## 5. Train

```python
@tf.function
def train_step(images):
    
    noise = tf.random.uniform([BATCH_SIZE, noise_dim])
    
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)
        
        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)
        
        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)
    
    GenWeights = generator.trainable_variables
    DiscWeights = discriminator.trainable_variables
    
    gradients_of_generator = gen_tape.gradient(gen_loss, GenWeights)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, DiscWeights)
    
    generator_optimizer.apply_gradients(zip(gradients_of_generator, GenWeights))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, DiscWeights))
```

```python
# display generated images
def generate_and_save_images(model, epoch, test_input):
    
    predictions = model(test_input, training=False)
    
    fig = plt.figure(figsize=(4,4))
    for i in range(predictions.shape[0]):
        plt.subplot(4,4,i+1)
        plt.imshow(predictions[i, :, :, 0]*255, cmap='gray')
        plt.axis('off')
    plt.savefig('a_images/image_at_epoch_{:04d}.png'.format(epoch))
    plt.show()
```

```python
import time
from IPython import display 

# train GAN
def train(dataset, epochs):
    
    for epoch in range(epochs):
        start = time.time()
        
        for image_batch in dataset:
            train_step(image_batch)
        
        display.clear_output(wait=True)
        generate_and_save_images(generator, epoch+1, seed)
        
        if (epoch+1)%20 == 0:
            checkpoint.save(file_prefix=checkpoint_prefix)
        print(f'Time for epoch {epoch+1} is {time.time()-start} sec')
    
    display.clear_ouput(wait=True)
    generate_and_save_images(generator, epochs, seed)
```

## CycleGAN
![cycleGAN_structure](https://user-images.githubusercontent.com/61719257/148213058-d3e1ef9c-645e-4da2-bd22-86343fe1f89c.gif)
